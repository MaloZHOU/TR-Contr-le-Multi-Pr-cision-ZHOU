# Note1220

### Déjà fait:

- Ajouter quelques commentaire dans goddard.jl et goddard_Hermite_Simpson.jl, pour bien rédiger les paramètres.
- Créer un script de comparaison des trois dimension des hyperparamètres (Voir 4ème Problèmes & Trouvées)
- Commencer l'article "Controllability and Observability"



### À faire:

- 3 Articles à lire, commencer par "Controllability and Observability Imply Exponential Decay of Sensitivity in Dynamic Optimization"

- Ch16 de Jorge Nocedal.

- Essayer de modification de Runge-Kutta: mettre les dimensions supplémentaire directement aux $\bold{k_n}$ et définir chaque fonction dynamique

- Établir une bibliothèque de zotera pour les articles à ce moment.

- Un petit GUI pour mieux comparer les effets de tolérance, de nombre de discrétisation et de epsilon

  


### Problèmes & Trouvées: 

- Grande vision de la trace: Traduire le problème de contrôle sous forme d'optimisation numérique, finalement matricielle, et trouver la contradiction entre la condition SOSC (selon le premier article) et (peut-être) les conditions d'inégalité et commandabilité de Goddard.
- Pour conditions de KKT, qualification des contraintes, voire ch5 de Poly_Optimisation notamment 5.5.1pour Qualification de contrainte, p52 pour QC-IL, P53 pour KKT d'ordre 2.
- Pour HSL, il ne faut pas d'avoir un nombre de discrétisation très grand, notamment nh=15000 va demander une mémoire plus grande que le maximum, voir Notes/prob_1220, en utilisant ma 27 et ma 57
- Il y a actuellement 3 hyperparamètre à modifier: nombre de discrétisation nh, tolérance tol et coefficient de quadratique $\epsilon$ . Pour savoir leurs tendances données, il faut donc faire une comparaison complet.
